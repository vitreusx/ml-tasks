{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_numeric_dtype, is_datetime64_any_dtype\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import scipy.fftpack\n",
    "import scipy.interpolate\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_context('notebook')\n",
    "%matplotlib widget\n",
    "\n",
    "import ipywidgets as widgets\n",
    "%gui asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('bank-classification.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It might we wise to first take a broad look at the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>birth_date</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact_date</th>\n",
       "      <th>contact</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1952-03-23</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2008-05-12</td>\n",
       "      <td>telephone</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1951-03-24</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2008-05-26</td>\n",
       "      <td>telephone</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1971-05-19</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2008-05-05</td>\n",
       "      <td>telephone</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1968-01-24</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2008-05-19</td>\n",
       "      <td>telephone</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1952-05-11</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2008-05-19</td>\n",
       "      <td>telephone</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  birth_date        job  marital    education  default housing loan  \\\n",
       "0   1  1952-03-23  housemaid  married     basic.4y       no      no   no   \n",
       "1   2  1951-03-24   services  married  high.school  unknown      no   no   \n",
       "2   3  1971-05-19   services  married  high.school       no     yes   no   \n",
       "3   4  1968-01-24     admin.  married     basic.6y       no      no   no   \n",
       "4   5  1952-05-11   services  married  high.school       no      no  yes   \n",
       "\n",
       "  contact_date    contact  campaign  pdays  previous     poutcome        y  \n",
       "0   2008-05-12  telephone         1    999         0  nonexistent       no  \n",
       "1   2008-05-26  telephone         1    999         0  nonexistent  unknown  \n",
       "2   2008-05-05  telephone         1    999         0  nonexistent       no  \n",
       "3   2008-05-19  telephone         1    999         0  nonexistent  unknown  \n",
       "4   2008-05-19  telephone         1    999         0  nonexistent  unknown  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>birth_date</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact_date</th>\n",
       "      <th>contact</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>41188.00000</td>\n",
       "      <td>41188</td>\n",
       "      <td>41188</td>\n",
       "      <td>41188</td>\n",
       "      <td>41188</td>\n",
       "      <td>41188</td>\n",
       "      <td>41188</td>\n",
       "      <td>41188</td>\n",
       "      <td>41188</td>\n",
       "      <td>41188</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188</td>\n",
       "      <td>41188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>13290</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>552</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1977-07-11</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2008-05-21</td>\n",
       "      <td>cellular</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>10422</td>\n",
       "      <td>24928</td>\n",
       "      <td>12168</td>\n",
       "      <td>32588</td>\n",
       "      <td>21576</td>\n",
       "      <td>33950</td>\n",
       "      <td>457</td>\n",
       "      <td>26144</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35563</td>\n",
       "      <td>20389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>20594.50000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.567593</td>\n",
       "      <td>962.475454</td>\n",
       "      <td>0.172963</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11890.09578</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.770014</td>\n",
       "      <td>186.910907</td>\n",
       "      <td>0.494901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10297.75000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>20594.50000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>30891.25000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>41188.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  birth_date     job  marital          education default  \\\n",
       "count   41188.00000       41188   41188    41188              41188   41188   \n",
       "unique          NaN       13290      12        4                  8       3   \n",
       "top             NaN  1977-07-11  admin.  married  university.degree      no   \n",
       "freq            NaN          16   10422    24928              12168   32588   \n",
       "mean    20594.50000         NaN     NaN      NaN                NaN     NaN   \n",
       "std     11890.09578         NaN     NaN      NaN                NaN     NaN   \n",
       "min         1.00000         NaN     NaN      NaN                NaN     NaN   \n",
       "25%     10297.75000         NaN     NaN      NaN                NaN     NaN   \n",
       "50%     20594.50000         NaN     NaN      NaN                NaN     NaN   \n",
       "75%     30891.25000         NaN     NaN      NaN                NaN     NaN   \n",
       "max     41188.00000         NaN     NaN      NaN                NaN     NaN   \n",
       "\n",
       "       housing   loan contact_date   contact      campaign         pdays  \\\n",
       "count    41188  41188        41188     41188  41188.000000  41188.000000   \n",
       "unique       3      3          552         2           NaN           NaN   \n",
       "top        yes     no   2008-05-21  cellular           NaN           NaN   \n",
       "freq     21576  33950          457     26144           NaN           NaN   \n",
       "mean       NaN    NaN          NaN       NaN      2.567593    962.475454   \n",
       "std        NaN    NaN          NaN       NaN      2.770014    186.910907   \n",
       "min        NaN    NaN          NaN       NaN      1.000000      0.000000   \n",
       "25%        NaN    NaN          NaN       NaN      1.000000    999.000000   \n",
       "50%        NaN    NaN          NaN       NaN      2.000000    999.000000   \n",
       "75%        NaN    NaN          NaN       NaN      3.000000    999.000000   \n",
       "max        NaN    NaN          NaN       NaN     56.000000    999.000000   \n",
       "\n",
       "            previous     poutcome        y  \n",
       "count   41188.000000        41188    41188  \n",
       "unique           NaN            3        3  \n",
       "top              NaN  nonexistent  unknown  \n",
       "freq             NaN        35563    20389  \n",
       "mean        0.172963          NaN      NaN  \n",
       "std         0.494901          NaN      NaN  \n",
       "min         0.000000          NaN      NaN  \n",
       "25%         0.000000          NaN      NaN  \n",
       "50%         0.000000          NaN      NaN  \n",
       "75%         0.000000          NaN      NaN  \n",
       "max         7.000000          NaN      NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all', datetime_is_numeric=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get to the more sophisticated analysis:\n",
    "- `id` is not a feature, and besides *pandas* already stores it;\n",
    "- we should also specify the types of features for cleaner further processing;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype({\n",
    "    'birth_date': 'datetime64',\n",
    "    'job': 'category',\n",
    "    'marital': 'category',\n",
    "    'education': 'category',\n",
    "    'default': 'category',\n",
    "    'housing': 'category',\n",
    "    'loan': 'category',\n",
    "    'contact_date': 'datetime64',\n",
    "    'contact': 'category',\n",
    "    'campaign': 'int64',\n",
    "    'pdays': 'int64',\n",
    "    'previous': 'int64',\n",
    "    'poutcome': 'category',\n",
    "    'y': 'category'\n",
    "})\n",
    "df.pop('id');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Known/Unknown\n",
    "We expect that the records without `y` value were drawn uniformly from the original dataset; we will, however, need the records with known `y` value for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_known = df[df['y'] != 'unknown'].copy()\n",
    "yn_dt = CategoricalDtype(categories=['no', 'yes'], ordered=True)\n",
    "df_known['y'] = df_known['y'].astype(yn_dt)\n",
    "\n",
    "df_unknown = df[df['y'] == 'unknown']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dates\n",
    "Let's start with the high-level overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42eb9384f10144fdb31baa0e1d4053fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "date_cols = [col for col, dtype in df.dtypes.items()\n",
    "                 if is_datetime64_any_dtype(dtype)]\n",
    "\n",
    "fig, axes = plt.subplots(2, len(date_cols))\n",
    "\n",
    "for i, col in enumerate(date_cols):\n",
    "    sns.histplot(data=df_known, x=col, hue='y',\n",
    "                 multiple='stack', ax=axes[0][i])\n",
    "    sns.histplot(data=df_known, x=col, hue='y',\n",
    "                 multiple='fill', ax=axes[1][i])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, there would, in fact, seem to be a number of correlations:\n",
    "- \"middle-aged\" people are less likely to subscribe the term deposit;\n",
    "- latter campaigns seemingly were more effective (though they also did contact less people in general).\n",
    "\n",
    "We will add (interpolated) success rates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def success_rate(col):\n",
    "    samples = df[[col, 'y']]\n",
    "    samples_avg = pd.crosstab(samples[col], samples['y'])\n",
    "    \n",
    "    avg = samples_avg['yes'] / (samples_avg['yes'] + samples_avg['no'])\n",
    "    return scipy.interpolate.interp1d(samples_avg.index, avg, fill_value='extrapolate')\n",
    "\n",
    "for col in ['contact_date', 'birth_date']:\n",
    "    df['{}_D'.format(col)] = (df[col] - df[col].min()) / np.timedelta64(1, 'D')\n",
    "#     df['{}_rate'.format(cof ol)] = success_rate(col)(df['{}_D'.format(col)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check whether there is any periodic pattern to the `contact_date`. Let's start by checking the success rate per day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59a61e1f5d6443e4acba1d48b1817241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8aa8180d60>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "days = df['contact_date_D']\n",
    "full_days = np.arange(days.min(), days.max())\n",
    "full_avg = success_rate('contact_date_D')(full_days)\n",
    "\n",
    "ax.plot(full_days, full_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ace56674f6494d7b9846cd2b39336a9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8aa80b4df0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_f = scipy.fftpack.fft(full_avg)\n",
    "x_f = np.linspace(0, 1, len(avg_f))\n",
    "n = len(x_f)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x_f[:n//2], np.abs(avg_f[:n//2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, for the most part there is no frequency (as expected), but we could add that of 1/week for good measure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pdays`\n",
    "If we read the description of the dataset, `pdays==999` means that there was no prior contact - let us create a new feature with that information explicitly. We shall fill the `999`s with the mean of the valid values. **Note to self: could make it a hyperparameter.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pcontacted'] = df['pdays'] != 999\n",
    "df.loc[-df['pcontacted'], 'pdays'] = df.loc[df['pcontacted'], 'pdays'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical data\n",
    "Let's take a look at the categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b2eb993573fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m cat_cols = [col for col, dtype in df.dtypes.items()\n\u001b[0m\u001b[1;32m      2\u001b[0m                 if isinstance(dtype, CategoricalDtype)]\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m sel = widgets.Select(\n\u001b[1;32m      5\u001b[0m     \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcat_cols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "cat_cols = [col for col, dtype in df.dtypes.items()\n",
    "                if isinstance(dtype, CategoricalDtype)]\n",
    "\n",
    "sel = widgets.Select(\n",
    "    options=cat_cols,\n",
    "    value=cat_cols[0],\n",
    "    description='Columns: ',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "ok = widgets.Button(\n",
    "    description='Render',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    tooltip='Render',\n",
    "    icon='check'\n",
    ")\n",
    "\n",
    "display(sel, ok)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "def render(col):\n",
    "    ax1.clear()\n",
    "    sns.countplot(data=df_known, x=col, hue='y',\n",
    "                  ax=ax1)\n",
    "    ax2.clear()\n",
    "    sns.histplot(data=df_known, x=col, hue='y',\n",
    "                 multiple='fill', ax=ax2)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def on_click(_):\n",
    "    ok.description = 'Rendering...'\n",
    "    render(sel.value)\n",
    "    ok.description = 'Render'\n",
    "ok.on_click(on_click)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also take a look at the correlations between the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>job</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.054107</td>\n",
       "      <td>0.224722</td>\n",
       "      <td>-0.110841</td>\n",
       "      <td>0.009176</td>\n",
       "      <td>-0.002210</td>\n",
       "      <td>0.074300</td>\n",
       "      <td>0.080167</td>\n",
       "      <td>0.106257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marital</th>\n",
       "      <td>0.054107</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.039987</td>\n",
       "      <td>-0.083923</td>\n",
       "      <td>0.006507</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.032073</td>\n",
       "      <td>0.019019</td>\n",
       "      <td>0.018560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>0.224722</td>\n",
       "      <td>0.039987</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.139296</td>\n",
       "      <td>0.012397</td>\n",
       "      <td>0.006066</td>\n",
       "      <td>0.087734</td>\n",
       "      <td>0.014760</td>\n",
       "      <td>0.032035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>default</th>\n",
       "      <td>-0.110841</td>\n",
       "      <td>-0.083923</td>\n",
       "      <td>-0.139296</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.017227</td>\n",
       "      <td>0.004623</td>\n",
       "      <td>-0.137086</td>\n",
       "      <td>-0.105978</td>\n",
       "      <td>-0.098255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>housing</th>\n",
       "      <td>0.009176</td>\n",
       "      <td>0.006507</td>\n",
       "      <td>0.012397</td>\n",
       "      <td>-0.017227</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.287551</td>\n",
       "      <td>0.056005</td>\n",
       "      <td>0.021123</td>\n",
       "      <td>0.012288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan</th>\n",
       "      <td>-0.002210</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.006066</td>\n",
       "      <td>0.004623</td>\n",
       "      <td>0.287551</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.005917</td>\n",
       "      <td>0.001633</td>\n",
       "      <td>-0.000605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contact</th>\n",
       "      <td>0.074300</td>\n",
       "      <td>0.032073</td>\n",
       "      <td>0.087734</td>\n",
       "      <td>-0.137086</td>\n",
       "      <td>0.056005</td>\n",
       "      <td>-0.005917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.225982</td>\n",
       "      <td>0.146894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poutcome</th>\n",
       "      <td>0.080167</td>\n",
       "      <td>0.019019</td>\n",
       "      <td>0.014760</td>\n",
       "      <td>-0.105978</td>\n",
       "      <td>0.021123</td>\n",
       "      <td>0.001633</td>\n",
       "      <td>0.225982</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.269565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>0.106257</td>\n",
       "      <td>0.018560</td>\n",
       "      <td>0.032035</td>\n",
       "      <td>-0.098255</td>\n",
       "      <td>0.012288</td>\n",
       "      <td>-0.000605</td>\n",
       "      <td>0.146894</td>\n",
       "      <td>0.269565</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                job   marital  education   default   housing      loan  \\\n",
       "job        1.000000  0.054107   0.224722 -0.110841  0.009176 -0.002210   \n",
       "marital    0.054107  1.000000   0.039987 -0.083923  0.006507  0.000165   \n",
       "education  0.224722  0.039987   1.000000 -0.139296  0.012397  0.006066   \n",
       "default   -0.110841 -0.083923  -0.139296  1.000000 -0.017227  0.004623   \n",
       "housing    0.009176  0.006507   0.012397 -0.017227  1.000000  0.287551   \n",
       "loan      -0.002210  0.000165   0.006066  0.004623  0.287551  1.000000   \n",
       "contact    0.074300  0.032073   0.087734 -0.137086  0.056005 -0.005917   \n",
       "poutcome   0.080167  0.019019   0.014760 -0.105978  0.021123  0.001633   \n",
       "y          0.106257  0.018560   0.032035 -0.098255  0.012288 -0.000605   \n",
       "\n",
       "            contact  poutcome         y  \n",
       "job        0.074300  0.080167  0.106257  \n",
       "marital    0.032073  0.019019  0.018560  \n",
       "education  0.087734  0.014760  0.032035  \n",
       "default   -0.137086 -0.105978 -0.098255  \n",
       "housing    0.056005  0.021123  0.012288  \n",
       "loan      -0.005917  0.001633 -0.000605  \n",
       "contact    1.000000  0.225982  0.146894  \n",
       "poutcome   0.225982  1.000000  0.269565  \n",
       "y          0.146894  0.269565  1.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F = df_known.loc[:,cat_cols].apply(lambda x: pd.factorize(x)[0])\n",
    "F.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At any rate, nothing conclusive can be gained from the analysis. I will therefore, for each categorical variable:\n",
    "- add one-hot encodings thereof;\n",
    "- attach a variable with success rate associated with the encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [col for col, dtype in df.dtypes.items()\n",
    "                if isinstance(dtype, CategoricalDtype) and col != 'y']\n",
    "\n",
    "for col in cat_cols:\n",
    "#     counts = pd.crosstab(df[col], df['y'])\n",
    "#     counts_for_col = counts.loc[df[col],:]\n",
    "#     rate = counts_for_col['yes'] / (counts_for_col['yes'] + counts_for_col['no'])\n",
    "#     rate = pd.DataFrame(rate.values, columns=['{}__rate'.format(col)])\n",
    "    \n",
    "    cols = pd.get_dummies(df[col], prefix=col)    \n",
    "    df = pd.concat([df, cols], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of this gives us following columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "birth_date                       datetime64[ns]\n",
       "job                                    category\n",
       "marital                                category\n",
       "education                              category\n",
       "default                                category\n",
       "housing                                category\n",
       "loan                                   category\n",
       "contact_date                     datetime64[ns]\n",
       "contact                                category\n",
       "campaign                                  int64\n",
       "pdays                                   float64\n",
       "previous                                  int64\n",
       "poutcome                               category\n",
       "y                                      category\n",
       "contact_date_D                          float64\n",
       "birth_date_D                            float64\n",
       "pcontacted                                 bool\n",
       "job_admin.                                uint8\n",
       "job_blue-collar                           uint8\n",
       "job_entrepreneur                          uint8\n",
       "job_housemaid                             uint8\n",
       "job_management                            uint8\n",
       "job_retired                               uint8\n",
       "job_self-employed                         uint8\n",
       "job_services                              uint8\n",
       "job_student                               uint8\n",
       "job_technician                            uint8\n",
       "job_unemployed                            uint8\n",
       "job_unknown                               uint8\n",
       "marital_divorced                          uint8\n",
       "marital_married                           uint8\n",
       "marital_single                            uint8\n",
       "marital_unknown                           uint8\n",
       "education_basic.4y                        uint8\n",
       "education_basic.6y                        uint8\n",
       "education_basic.9y                        uint8\n",
       "education_high.school                     uint8\n",
       "education_illiterate                      uint8\n",
       "education_professional.course             uint8\n",
       "education_university.degree               uint8\n",
       "education_unknown                         uint8\n",
       "default_no                                uint8\n",
       "default_unknown                           uint8\n",
       "default_yes                               uint8\n",
       "housing_no                                uint8\n",
       "housing_unknown                           uint8\n",
       "housing_yes                               uint8\n",
       "loan_no                                   uint8\n",
       "loan_unknown                              uint8\n",
       "loan_yes                                  uint8\n",
       "contact_cellular                          uint8\n",
       "contact_telephone                         uint8\n",
       "poutcome_failure                          uint8\n",
       "poutcome_nonexistent                      uint8\n",
       "poutcome_success                          uint8\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test datasets\n",
    "First, we remove non-numeric values; then, we split the dataset by `y`-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_num(_df):\n",
    "    numeric_cols = _df.dtypes[_df.dtypes.apply(is_numeric_dtype)]\n",
    "    return _df[numeric_cols.index].astype('float64')\n",
    "\n",
    "features = df.copy()\n",
    "labels = features.pop('y')\n",
    "\n",
    "train_Ix = (labels != 'unknown')\n",
    "\n",
    "train_features = features[train_Ix]\n",
    "train_features = extract_num(train_features)\n",
    "\n",
    "train_labels = labels[train_Ix]\n",
    "train_labels = pd.DataFrame(train_labels.astype(yn_dt).cat.codes,\n",
    "                            columns=['y'])\n",
    "\n",
    "test_Ix = (labels == 'unknown')\n",
    "test_features = features[test_Ix]\n",
    "test_features = extract_num(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us also define some utility functions for further splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def _choose_Ix(train, n):\n",
    "    train_n = int(np.ceil(train*n))\n",
    "    train_Ix = np.random.choice(n, train_n, replace=False)\n",
    "    test_Ix = np.setdiff1d(np.arange(n), train_Ix)\n",
    "    return train_Ix, test_Ix\n",
    "\n",
    "def split(train, X=train_features, y=train_labels):\n",
    "    train_Ix, test_Ix = _choose_Ix(train, X.shape[0])\n",
    "    np.random.shuffle(train_Ix)\n",
    "    np.random.shuffle(test_Ix)    \n",
    "    \n",
    "    return X.iloc[train_Ix,:], y.iloc[train_Ix,:],\\\n",
    "           X.iloc[test_Ix,:], y.iloc[test_Ix,:]\n",
    "\n",
    "def choose(frac, X=train_features, y=train_labels):\n",
    "    train_Ix, _ = _choose_Ix(frac, X.shape[0])\n",
    "    np.random.shuffle(train_Ix)\n",
    "    return X.iloc[train_Ix,:], y.iloc[train_Ix,:]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model № 1 (Sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_validate, RandomizedSearchCV,\\\n",
    "    GridSearchCV\n",
    "import tempfile\n",
    "\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import SGDClassifier, RidgeClassifierCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.ensemble import\\\n",
    "    AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier,\\\n",
    "    StackingClassifier, HistGradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_selection import SelectKBest, chi2, SelectFromModel\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will essentially stack a bunch of various (sometimes boosting) models; we will also attach hyperparameters for use in the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = {\n",
    "#     'svc': {\n",
    "#         'clf': SVC(kernel='rbf', C=1),\n",
    "#         'grid': {\n",
    "#             'kernel': ['rbf', 'poly', 'sigmoid', 'linear'],\n",
    "#             'C': [0.1, 1, 10, 40, 100],\n",
    "#             'gamma': ['auto', 1, 0.1, 0.01]\n",
    "#         }\n",
    "#     },\n",
    "    'rf': {\n",
    "        'clf': RandomForestClassifier(),\n",
    "        'grid': {\n",
    "            'max_features': ['auto', 'sqrt', 'log2'],\n",
    "            'n_estimators': [10, 100, 250, 1000],\n",
    "        }\n",
    "    },\n",
    "    'et': {\n",
    "        'clf': ExtraTreesClassifier(),\n",
    "        'grid': {\n",
    "            'n_estimators': [*range(50, 250+1, 50), 1000],\n",
    "            'max_features': ['auto', 'sqrt', 'log2'],\n",
    "            'min_samples_leaf': [*range(1, 10+1, 2), *range(20, 50+1, 5)],\n",
    "            'min_samples_split': [*range(1, 10+1, 2), *range(15, 35+1, 5)]\n",
    "        }\n",
    "    },\n",
    "    'gbc': {\n",
    "        'clf': GradientBoostingClassifier(),\n",
    "        'grid': {\n",
    "            'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "            'n_estimators': [10, 100, 250, 1000],\n",
    "            'min_samples_split': [100, 250, 500, 1000],\n",
    "            'max_features': ['auto', 'log2', 'sqrt'],\n",
    "            'max_depth': [*range(5, 8+1)],\n",
    "            'subsample': [0.5, 0.7, 1],\n",
    "        }\n",
    "    },\n",
    "    'ada': {\n",
    "        'clf': AdaBoostClassifier(),\n",
    "        'grid': {\n",
    "            'n_estimators': [10, 50, 100, 500],\n",
    "            'learning_rate': [0.01, 0.1, 0.5, 1, 2],\n",
    "            'base_estimator': [DecisionTreeClassifier(max_depth = n)\n",
    "                                    for n in [*range(1, 16+1)]]    \n",
    "        }\n",
    "    },\n",
    "    'xgb': {\n",
    "        'clf': XGBClassifier(use_label_encoder=False,\n",
    "                             eval_metric='logloss'),\n",
    "        'grid': {\n",
    "#             'n_estimators': [10, 50, 100, 500],\n",
    "#             'learning_rate': [.02, .05, .1],\n",
    "#             'max_depth': [4, 6, 8, 10],\n",
    "        }\n",
    "    },\n",
    "    'bayes': {\n",
    "        'clf': GaussianNB(),\n",
    "        'grid': {}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is about the hyperparameter search. For obvious reasons, we shall skip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import copy\n",
    "\n",
    "def load_models():\n",
    "    return pickle.load(open('sklearn-models', 'rb'))\n",
    "\n",
    "def save_models(est):\n",
    "    pickle.save(est, open('sklearn-models', 'wb'))\n",
    "\n",
    "def search(X_train, y_train):\n",
    "    MAX_N_ITER = 200\n",
    "    estimators = copy.deepcopy(base)\n",
    "    \n",
    "    for name, params in base.items():\n",
    "        estimators[name] = {'clf': params['clf']}\n",
    "        if params['grid'] != {}:\n",
    "            cv = RandomizedSearchCV(params['clf'], params['grid'],\n",
    "                                   n_iter=MAX_N_ITER, scoring='roc_auc',\n",
    "                                   cv=5, n_jobs=-1, verbose=10)\n",
    "            result = cv.fit(X_train, y_train)\n",
    "            estimators[name]['result'] = result\n",
    "            estimators[name]['clf'] = result.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where we shall actually train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/home/talos/devs/venvs/py38/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................. , roc_auc=0.782, total=  19.3s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   19.3s remaining:    0.0s\n",
      "/home/talos/devs/venvs/py38/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................. , roc_auc=0.787, total=  19.6s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   38.9s remaining:    0.0s\n",
      "/home/talos/devs/venvs/py38/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................. , roc_auc=0.781, total=  21.0s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   60.0s remaining:    0.0s\n",
      "/home/talos/devs/venvs/py38/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................. , roc_auc=0.785, total=  21.9s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  1.4min remaining:    0.0s\n",
      "/home/talos/devs/venvs/py38/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................. , roc_auc=0.791, total=  23.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.7min finished\n"
     ]
    }
   ],
   "source": [
    "estimators = base\n",
    "\n",
    "cache = tempfile.TemporaryDirectory()\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('stacked', StackingClassifier(\n",
    "        estimators=[(name, params['clf'])\n",
    "                    for name, params in estimators.items()],\n",
    "        final_estimator=GradientBoostingClassifier(),\n",
    "        n_jobs=2))\n",
    "], memory=str(cache))\n",
    "\n",
    "X_train, y_train, _, _ = split(1)\n",
    "score = cross_validate(clf, X_train, y_train,\n",
    "                       cv=5, scoring=['roc_auc'], verbose=10,\n",
    "                       return_estimator=True)\n",
    "\n",
    "if 'models' not in vars():\n",
    "    models = []\n",
    "models = [*models, score]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For dev purposes, we will present some stats about individual classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {name: cross_validate(clf['clf'], X_train, y_train,\n",
    "                               cv=5, scoring=['roc_auc'])\n",
    "          for name, clf in estimators.items()}\n",
    "scores = {**scores, 'stacked': score}\n",
    "\n",
    "score_list = []\n",
    "for name, score in scores.items():\n",
    "    for stat in ['fit_time', 'score_time', 'test_roc_auc']:\n",
    "        for val in score[stat]:\n",
    "            score_list.append([name, stat, val])\n",
    "\n",
    "score_df = pd.DataFrame(data=score_list,\n",
    "                        columns=['est', 'stat', 'val'])\n",
    "\n",
    "sns.catplot(data=score_df, x='est', hue='stat', y='val',\n",
    "            kind='box')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let us save the predictions to a .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pred_sk(clf, name):\n",
    "    pred_df = pd.DataFrame(columns=['id', 'y'])\n",
    "    pred_df['id'] = test_features.index+1\n",
    "    pred_df['y'] = clf.predict_proba(test_features)[:,1]\n",
    "    pred_df.to_csv('pred.{}.csv'.format(name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pred_sk(clf.fit(X_train, y_train), 'scaledv2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model № 2 (TF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the definition of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 2048\n",
    "DROPOUT = 0.5\n",
    "\n",
    "def block(x_in, size):\n",
    "    x = layers.Dense(size)(x_in)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Dropout(DROPOUT)(x)\n",
    "    return x\n",
    "\n",
    "def create_model(shape):\n",
    "    x_in = layers.Input(shape=shape)\n",
    "    x = block(x_in, 2048)\n",
    "    x_out = layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = keras.Model(inputs=x_in, outputs=x_out)    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(lr=1e-3),\n",
    "        loss=keras.losses.BinaryCrossentropy(),\n",
    "        metrics=[keras.metrics.AUC(name='auc')])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will want to balance the predictors in this particular case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_post, y_post = split(0.9)\n",
    "X_train, y_train, X_test, y_test = split(0.8, X_train, y_train)\n",
    "\n",
    "resample = False\n",
    "\n",
    "if resample:\n",
    "    neg_features = X_train[y_train == 0]\n",
    "    neg_labels = y_train[y_train == 0]\n",
    "    pos_features = X_train[y_train == 1]\n",
    "    pos_labels = y_train[y_train == 1]\n",
    "\n",
    "    def make_ds(features, labels):\n",
    "        ds = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "        ds = ds.shuffle(100000).repeat()\n",
    "        return ds\n",
    "\n",
    "    neg_ds = make_ds(neg_features, neg_labels)\n",
    "    pos_ds = make_ds(pos_features, pos_labels)\n",
    "\n",
    "    train_ds = tf.data.experimental.\\\n",
    "        sample_from_datasets([neg_ds, pos_ds], weights=[0.5, 0.5])\n",
    "    train_ds = train_ds.batch(BATCH_SIZE).prefetch(2)\n",
    "    \n",
    "    pos = np.sum(y_train)\n",
    "    total = np.size(y_train)\n",
    "    neg = total - pos\n",
    "    resampled_steps_per_epoch = np.ceil(2.0*neg/BATCH_SIZE)\n",
    "else:    \n",
    "    train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).cache()\n",
    "    train_ds = train_ds.batch(BATCH_SIZE).prefetch(2)\n",
    "\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).cache()\n",
    "val_ds = val_ds.batch(BATCH_SIZE).prefetch(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.4752 - auc: 0.5747 - val_loss: 1.0985 - val_auc: 0.6262\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.4111 - auc: 0.6503 - val_loss: 0.5130 - val_auc: 0.7396\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 0.3912 - auc: 0.6550 - val_loss: 0.4985 - val_auc: 0.7374\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.3765 - auc: 0.6757 - val_loss: 0.3973 - val_auc: 0.7254\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.3743 - auc: 0.6796 - val_loss: 0.4123 - val_auc: 0.7080\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.3706 - auc: 0.6813 - val_loss: 0.5388 - val_auc: 0.6693\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.3640 - auc: 0.6887 - val_loss: 0.6426 - val_auc: 0.6555\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.3632 - auc: 0.6885 - val_loss: 0.6254 - val_auc: 0.6533\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.3604 - auc: 0.6927 - val_loss: 0.5880 - val_auc: 0.6665\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.3591 - auc: 0.6955 - val_loss: 0.8099 - val_auc: 0.5975\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.3578 - auc: 0.6948 - val_loss: 0.8952 - val_auc: 0.5818\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.3506 - auc: 0.6996 - val_loss: 0.8980 - val_auc: 0.5826\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.3503 - auc: 0.6993 - val_loss: 0.8910 - val_auc: 0.5719\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.3421 - auc: 0.7163 - val_loss: 0.9577 - val_auc: 0.5687\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.3400 - auc: 0.7160 - val_loss: 0.9036 - val_auc: 0.5684\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.3466 - auc: 0.7068 - val_loss: 0.8516 - val_auc: 0.5643\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.3386 - auc: 0.7184 - val_loss: 0.7979 - val_auc: 0.5668\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.3412 - auc: 0.7127 - val_loss: 0.6916 - val_auc: 0.5936\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.3396 - auc: 0.7141 - val_loss: 0.7030 - val_auc: 0.5872\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.3339 - auc: 0.7193 - val_loss: 0.7327 - val_auc: 0.5730\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.3358 - auc: 0.7192 - val_loss: 0.6664 - val_auc: 0.5833\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.3344 - auc: 0.7249 - val_loss: 0.6415 - val_auc: 0.5832\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.3310 - auc: 0.7244 - val_loss: 0.6372 - val_auc: 0.5840\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.3307 - auc: 0.7240 - val_loss: 0.5970 - val_auc: 0.5981\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 0.3327 - auc: 0.7197 - val_loss: 0.5510 - val_auc: 0.6108\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.3301 - auc: 0.7246 - val_loss: 0.5073 - val_auc: 0.6162\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.3318 - auc: 0.7233 - val_loss: 0.4938 - val_auc: 0.6162\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.3258 - auc: 0.7298 - val_loss: 0.4990 - val_auc: 0.6096\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.3265 - auc: 0.7278 - val_loss: 0.4822 - val_auc: 0.6146\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.3280 - auc: 0.7240 - val_loss: 0.4662 - val_auc: 0.6175\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.3221 - auc: 0.7321 - val_loss: 0.4440 - val_auc: 0.6235\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.3234 - auc: 0.7363 - val_loss: 0.4212 - val_auc: 0.6279\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.3228 - auc: 0.7369 - val_loss: 0.4067 - val_auc: 0.6331\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 0.3209 - auc: 0.7377 - val_loss: 0.4044 - val_auc: 0.6292\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.3229 - auc: 0.7336 - val_loss: 0.3896 - val_auc: 0.6387\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.3210 - auc: 0.7370 - val_loss: 0.3842 - val_auc: 0.6475\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.3217 - auc: 0.7379 - val_loss: 0.3612 - val_auc: 0.6704\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.3215 - auc: 0.7384 - val_loss: 0.3544 - val_auc: 0.6749\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.3208 - auc: 0.7365 - val_loss: 0.3514 - val_auc: 0.6921\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.3176 - auc: 0.7413 - val_loss: 0.3376 - val_auc: 0.7066\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.3164 - auc: 0.7472 - val_loss: 0.3349 - val_auc: 0.7113\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.3178 - auc: 0.7429 - val_loss: 0.3374 - val_auc: 0.7089\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.3201 - auc: 0.7386 - val_loss: 0.3365 - val_auc: 0.6995\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.3177 - auc: 0.7429 - val_loss: 0.3365 - val_auc: 0.7083\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.3153 - auc: 0.7478 - val_loss: 0.3524 - val_auc: 0.7323\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.3160 - auc: 0.7408 - val_loss: 0.3376 - val_auc: 0.7443\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.3182 - auc: 0.7393 - val_loss: 0.3413 - val_auc: 0.7457\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.3142 - auc: 0.7449 - val_loss: 0.3287 - val_auc: 0.7468\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.3157 - auc: 0.7438 - val_loss: 0.3365 - val_auc: 0.7530\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.3165 - auc: 0.7447 - val_loss: 0.3563 - val_auc: 0.7468\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.3096 - auc: 0.7540 - val_loss: 0.3481 - val_auc: 0.7559\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.3142 - auc: 0.7444 - val_loss: 0.3301 - val_auc: 0.7577\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.3135 - auc: 0.7471 - val_loss: 0.3241 - val_auc: 0.7521\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.3168 - auc: 0.7431 - val_loss: 0.3373 - val_auc: 0.7373\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.3161 - auc: 0.7446 - val_loss: 0.3316 - val_auc: 0.7371\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.3125 - auc: 0.7489 - val_loss: 0.3254 - val_auc: 0.7431\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.3126 - auc: 0.7472 - val_loss: 0.3190 - val_auc: 0.7484\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.3127 - auc: 0.7468 - val_loss: 0.3154 - val_auc: 0.7486\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.3147 - auc: 0.7447 - val_loss: 0.3110 - val_auc: 0.7563\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.3117 - auc: 0.7499 - val_loss: 0.3397 - val_auc: 0.7568\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.3098 - auc: 0.7517 - val_loss: 0.3722 - val_auc: 0.7536\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.3114 - auc: 0.7491 - val_loss: 0.3670 - val_auc: 0.7579\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.3098 - auc: 0.7517 - val_loss: 0.3836 - val_auc: 0.7556\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.3110 - auc: 0.7511 - val_loss: 0.4356 - val_auc: 0.7520\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.3101 - auc: 0.7494 - val_loss: 0.4420 - val_auc: 0.7477\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.3102 - auc: 0.7534 - val_loss: 0.4127 - val_auc: 0.7525\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.3120 - auc: 0.7525 - val_loss: 0.3961 - val_auc: 0.7564\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.3091 - auc: 0.7496 - val_loss: 0.3496 - val_auc: 0.7607\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.3099 - auc: 0.7528 - val_loss: 0.3210 - val_auc: 0.7644\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.3113 - auc: 0.7493 - val_loss: 0.3151 - val_auc: 0.7639\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.3109 - auc: 0.7508 - val_loss: 0.3256 - val_auc: 0.7609\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.3067 - auc: 0.7569 - val_loss: 0.3157 - val_auc: 0.7622\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.3086 - auc: 0.7568 - val_loss: 0.3117 - val_auc: 0.7619\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.3090 - auc: 0.7542 - val_loss: 0.3182 - val_auc: 0.7628\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.3101 - auc: 0.7532 - val_loss: 0.3105 - val_auc: 0.7654\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.3087 - auc: 0.7538 - val_loss: 0.3078 - val_auc: 0.7666\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.3054 - auc: 0.7590 - val_loss: 0.3147 - val_auc: 0.7661\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.3078 - auc: 0.7556 - val_loss: 0.3132 - val_auc: 0.7670\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.3078 - auc: 0.7560 - val_loss: 0.3090 - val_auc: 0.7669\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.3068 - auc: 0.7543 - val_loss: 0.3078 - val_auc: 0.7638\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.3091 - auc: 0.7536 - val_loss: 0.3083 - val_auc: 0.7652\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.3082 - auc: 0.7550 - val_loss: 0.3071 - val_auc: 0.7648\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.3071 - auc: 0.7580 - val_loss: 0.3074 - val_auc: 0.7660\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.3083 - auc: 0.7552 - val_loss: 0.3086 - val_auc: 0.7653\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.3074 - auc: 0.7557 - val_loss: 0.3111 - val_auc: 0.7669\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.3080 - auc: 0.7527 - val_loss: 0.3142 - val_auc: 0.7668\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.3055 - auc: 0.7588 - val_loss: 0.3253 - val_auc: 0.7649\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.3071 - auc: 0.7569 - val_loss: 0.3162 - val_auc: 0.7653\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.3070 - auc: 0.7572 - val_loss: 0.3130 - val_auc: 0.7676\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.3094 - auc: 0.7527 - val_loss: 0.3188 - val_auc: 0.7639\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.3066 - auc: 0.7574 - val_loss: 0.3287 - val_auc: 0.7629\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.3070 - auc: 0.7552 - val_loss: 0.3530 - val_auc: 0.7593\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.3057 - auc: 0.7577 - val_loss: 0.3491 - val_auc: 0.7629\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.3031 - auc: 0.7651 - val_loss: 0.3541 - val_auc: 0.7655\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.3049 - auc: 0.7618 - val_loss: 0.3443 - val_auc: 0.7645\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.3052 - auc: 0.7569 - val_loss: 0.3224 - val_auc: 0.7635\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.3062 - auc: 0.7578 - val_loss: 0.3077 - val_auc: 0.7686\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.3067 - auc: 0.7546 - val_loss: 0.3100 - val_auc: 0.7665\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 0.3040 - auc: 0.7634 - val_loss: 0.3085 - val_auc: 0.7647\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 0.3062 - auc: 0.7564 - val_loss: 0.3087 - val_auc: 0.7682\n"
     ]
    }
   ],
   "source": [
    "model = create_model(X_train.shape[1])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_auc', \n",
    "    verbose=1,\n",
    "    patience=10,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "#     steps_per_epoch=resampled_steps_per_epoch,\n",
    "#     callbacks=[early_stopping],\n",
    "    validation_data=val_ds,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7759658624421556"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7787348448423828"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7584259449848378"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.78082914761996"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7795726405250503"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7816499544548053"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.785616947580093"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7763063651325389"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7688686917062918"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7775788244453095"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    X, y = choose(0.2)\n",
    "    display(roc_auc_score(y, model.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let us save the predictions to a .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pred_tf(model, name):\n",
    "    pred_df = pd.DataFrame(columns=['id', 'y'])\n",
    "    pred_df['id'] = test_features.index+1\n",
    "    pred_df['y'] = model.predict(test_features)\n",
    "    pred_df.to_csv('pred.{}.csv'.format(name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pred_tf(model, 'tfv2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
