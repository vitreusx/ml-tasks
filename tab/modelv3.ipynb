{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(9001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I must be honest; I couldn't for the life of me figure out how to make it _precisely_ reproducible. Perhaps there are some other settings (specifically in `sklearn`) that use some other randomness source. The `model` used to generate the csv is precisely the same, though. I very much apologise for this inconvenience. At any rate,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_context('notebook')\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I worked on it in Jupyter Lab. In my estimation, `ipyml` (for `%matplotlib widget`) is fairly common -- if, however, there are problems with the graphics, I could prepare a Docker container for it (there was too little time as of writing this to procure such a container, however)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('bank-classification.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the data first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>birth_date</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact_date</th>\n",
       "      <th>contact</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1952-03-23</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2008-05-12</td>\n",
       "      <td>telephone</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1951-03-24</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2008-05-26</td>\n",
       "      <td>telephone</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1971-05-19</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2008-05-05</td>\n",
       "      <td>telephone</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1968-01-24</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2008-05-19</td>\n",
       "      <td>telephone</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1952-05-11</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2008-05-19</td>\n",
       "      <td>telephone</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41183</th>\n",
       "      <td>41184</td>\n",
       "      <td>1938-03-19</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2010-11-19</td>\n",
       "      <td>cellular</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41184</th>\n",
       "      <td>41185</td>\n",
       "      <td>1964-10-10</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2010-11-12</td>\n",
       "      <td>cellular</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41185</th>\n",
       "      <td>41186</td>\n",
       "      <td>1954-10-06</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2010-11-12</td>\n",
       "      <td>cellular</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41186</th>\n",
       "      <td>41187</td>\n",
       "      <td>1967-03-15</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2010-11-26</td>\n",
       "      <td>cellular</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41187</th>\n",
       "      <td>41188</td>\n",
       "      <td>1936-10-20</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2010-11-26</td>\n",
       "      <td>cellular</td>\n",
       "      <td>3</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41188 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  birth_date          job  marital            education  default  \\\n",
       "0          1  1952-03-23    housemaid  married             basic.4y       no   \n",
       "1          2  1951-03-24     services  married          high.school  unknown   \n",
       "2          3  1971-05-19     services  married          high.school       no   \n",
       "3          4  1968-01-24       admin.  married             basic.6y       no   \n",
       "4          5  1952-05-11     services  married          high.school       no   \n",
       "...      ...         ...          ...      ...                  ...      ...   \n",
       "41183  41184  1938-03-19      retired  married  professional.course       no   \n",
       "41184  41185  1964-10-10  blue-collar  married  professional.course       no   \n",
       "41185  41186  1954-10-06      retired  married    university.degree       no   \n",
       "41186  41187  1967-03-15   technician  married  professional.course       no   \n",
       "41187  41188  1936-10-20      retired  married  professional.course       no   \n",
       "\n",
       "      housing loan contact_date    contact  campaign  pdays  previous  \\\n",
       "0          no   no   2008-05-12  telephone         1    999         0   \n",
       "1          no   no   2008-05-26  telephone         1    999         0   \n",
       "2         yes   no   2008-05-05  telephone         1    999         0   \n",
       "3          no   no   2008-05-19  telephone         1    999         0   \n",
       "4          no  yes   2008-05-19  telephone         1    999         0   \n",
       "...       ...  ...          ...        ...       ...    ...       ...   \n",
       "41183     yes   no   2010-11-19   cellular         1    999         0   \n",
       "41184      no   no   2010-11-12   cellular         1    999         0   \n",
       "41185     yes   no   2010-11-12   cellular         2    999         0   \n",
       "41186      no   no   2010-11-26   cellular         1    999         0   \n",
       "41187     yes   no   2010-11-26   cellular         3    999         1   \n",
       "\n",
       "          poutcome        y  \n",
       "0      nonexistent       no  \n",
       "1      nonexistent  unknown  \n",
       "2      nonexistent       no  \n",
       "3      nonexistent  unknown  \n",
       "4      nonexistent  unknown  \n",
       "...            ...      ...  \n",
       "41183  nonexistent  unknown  \n",
       "41184  nonexistent  unknown  \n",
       "41185  nonexistent       no  \n",
       "41186  nonexistent  unknown  \n",
       "41187      failure       no  \n",
       "\n",
       "[41188 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>birth_date</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact_date</th>\n",
       "      <th>contact</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>41188.00000</td>\n",
       "      <td>41188</td>\n",
       "      <td>41188</td>\n",
       "      <td>41188</td>\n",
       "      <td>41188</td>\n",
       "      <td>41188</td>\n",
       "      <td>41188</td>\n",
       "      <td>41188</td>\n",
       "      <td>41188</td>\n",
       "      <td>41188</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188</td>\n",
       "      <td>41188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>13290</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>552</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1977-07-11</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2008-05-21</td>\n",
       "      <td>cellular</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>10422</td>\n",
       "      <td>24928</td>\n",
       "      <td>12168</td>\n",
       "      <td>32588</td>\n",
       "      <td>21576</td>\n",
       "      <td>33950</td>\n",
       "      <td>457</td>\n",
       "      <td>26144</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35563</td>\n",
       "      <td>20389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>20594.50000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.567593</td>\n",
       "      <td>962.475454</td>\n",
       "      <td>0.172963</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11890.09578</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.770014</td>\n",
       "      <td>186.910907</td>\n",
       "      <td>0.494901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10297.75000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>20594.50000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>30891.25000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>41188.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  birth_date     job  marital          education default  \\\n",
       "count   41188.00000       41188   41188    41188              41188   41188   \n",
       "unique          NaN       13290      12        4                  8       3   \n",
       "top             NaN  1977-07-11  admin.  married  university.degree      no   \n",
       "freq            NaN          16   10422    24928              12168   32588   \n",
       "mean    20594.50000         NaN     NaN      NaN                NaN     NaN   \n",
       "std     11890.09578         NaN     NaN      NaN                NaN     NaN   \n",
       "min         1.00000         NaN     NaN      NaN                NaN     NaN   \n",
       "25%     10297.75000         NaN     NaN      NaN                NaN     NaN   \n",
       "50%     20594.50000         NaN     NaN      NaN                NaN     NaN   \n",
       "75%     30891.25000         NaN     NaN      NaN                NaN     NaN   \n",
       "max     41188.00000         NaN     NaN      NaN                NaN     NaN   \n",
       "\n",
       "       housing   loan contact_date   contact      campaign         pdays  \\\n",
       "count    41188  41188        41188     41188  41188.000000  41188.000000   \n",
       "unique       3      3          552         2           NaN           NaN   \n",
       "top        yes     no   2008-05-21  cellular           NaN           NaN   \n",
       "freq     21576  33950          457     26144           NaN           NaN   \n",
       "mean       NaN    NaN          NaN       NaN      2.567593    962.475454   \n",
       "std        NaN    NaN          NaN       NaN      2.770014    186.910907   \n",
       "min        NaN    NaN          NaN       NaN      1.000000      0.000000   \n",
       "25%        NaN    NaN          NaN       NaN      1.000000    999.000000   \n",
       "50%        NaN    NaN          NaN       NaN      2.000000    999.000000   \n",
       "75%        NaN    NaN          NaN       NaN      3.000000    999.000000   \n",
       "max        NaN    NaN          NaN       NaN     56.000000    999.000000   \n",
       "\n",
       "            previous     poutcome        y  \n",
       "count   41188.000000        41188    41188  \n",
       "unique           NaN            3        3  \n",
       "top              NaN  nonexistent  unknown  \n",
       "freq             NaN        35563    20389  \n",
       "mean        0.172963          NaN      NaN  \n",
       "std         0.494901          NaN      NaN  \n",
       "min         0.000000          NaN      NaN  \n",
       "25%         0.000000          NaN      NaN  \n",
       "50%         0.000000          NaN      NaN  \n",
       "75%         0.000000          NaN      NaN  \n",
       "max         7.000000          NaN      NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               int64\n",
       "birth_date      object\n",
       "job             object\n",
       "marital         object\n",
       "education       object\n",
       "default         object\n",
       "housing         object\n",
       "loan            object\n",
       "contact_date    object\n",
       "contact         object\n",
       "campaign         int64\n",
       "pdays            int64\n",
       "previous         int64\n",
       "poutcome        object\n",
       "y               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, clearly the types could be set better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "integral = ['id', 'campaign', 'pdays', 'previous']\n",
    "datelike = ['birth_date', 'contact_date']\n",
    "categorical = ['job', 'marital', 'education', 'default',\n",
    "               'housing', 'contact', 'poutcome', 'loan', 'y']\n",
    "\n",
    "dtypes = {\n",
    "    **{col: 'int64' for col in integral},\n",
    "    **{col: 'datetime64' for col in datelike},\n",
    "    **{col: 'category' for col in categorical}\n",
    "}\n",
    "\n",
    "df = df.astype(dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                       int64\n",
       "birth_date      datetime64[ns]\n",
       "job                   category\n",
       "marital               category\n",
       "education             category\n",
       "default               category\n",
       "housing               category\n",
       "loan                  category\n",
       "contact_date    datetime64[ns]\n",
       "contact               category\n",
       "campaign                 int64\n",
       "pdays                    int64\n",
       "previous                 int64\n",
       "poutcome              category\n",
       "y                     category\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to:\n",
    "- preprocess the columns for use in models;\n",
    "- possibly add and/or remove new features.\n",
    "\n",
    "Our strategy is essentially as follows:\n",
    "- `id` is useless;\n",
    "- `birth_date` and `contact_date` must be converted to numerical values, for example days since the minimum;\n",
    "- `job`, `marital`, `education`, `default`, `housing`, `contact` and `poutcome` are categorical, and since the # of unique values is small, we will one-hot encode\n",
    "them;\n",
    "- `pdays` has a special \"missing\" value `999`;\n",
    "- `y` is the label.\n",
    "\n",
    "We *could* also input some extraneous values -- to that end, let us investigate the values more closely; specifically in relation to `y` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e9a83dd355d476d857f401c41f3ef7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Select(description='Column: ', options=('id', 'campaign', 'pdays', 'previous', 'birth_date', 'contact_date', 'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "299a5642ac964dfe8cb637475d5d3236",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Render', icon='check', style=ButtonStyle(), tooltip='Render')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8219c3e30c55437cbc15b065e2d1036b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "%gui asyncio\n",
    "\n",
    "cols = [*integral, *datelike, *categorical]\n",
    "selector = widgets.Select(\n",
    "    options=cols,\n",
    "    value=cols[0],\n",
    "    description='Column: ',\n",
    "    disabled=False)\n",
    "\n",
    "render_btn = widgets.Button(\n",
    "    description='Render',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    tooltip='Render',\n",
    "    icon='check')\n",
    "\n",
    "display(selector, render_btn)\n",
    "\n",
    "fig, (ax_abs, ax_rel) = plt.subplots(2, 1)\n",
    "\n",
    "known_df = df[df['y'] != 'unknown']\n",
    "\n",
    "def render(col):\n",
    "    ax_abs.clear()\n",
    "    sns.histplot(data=known_df, x=col, hue='y',\n",
    "                 multiple='stack', ax=ax_abs)    \n",
    "    ax_rel.clear()\n",
    "    sns.histplot(data=known_df, x=col, hue='y',\n",
    "                 multiple='fill', ax=ax_rel)\n",
    "    plt.show()\n",
    "\n",
    "def on_click(_):\n",
    "    render_btn.description = 'Rendering...'\n",
    "    render(selector.value)\n",
    "    render_btn.description = 'Render'\n",
    "render_btn.on_click(on_click)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, clearly there _are_ correlations; we cannot, however, use them explicitly (since the model would presumably overfit, and if anything be unrealistic, or at least that's what I got from the tests). The full scope of the feature engineering is as follows:\n",
    "- for dates, we add days since minimum (with \\log(1+x) and \\sqrt{x}), along with day of the week, day, month and year, to cover any possibly occuring periodic patterns.\n",
    "- for `pdays`, `999` represents the missing value; we shall replace it with the mean, and also add an indicator feature;\n",
    "- categorical features shall be one-hot encoded;\n",
    "- `id` will be dropped (there seems to actually be correlation with `y` at the first glance, if we look at the graph above, but the variable obviously cannot be indicative of anything but the order in the dataset).\n",
    "\n",
    "We will implement it all as a `sklearn` Transformer, for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class DateTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        self.names = []\n",
    "        dfs = []\n",
    "        for name in X:\n",
    "            col = X[name]\n",
    "            \n",
    "            days = (col-col.min()) / np.timedelta64(1, 'D')\n",
    "            days_log = np.log(1+days)\n",
    "            days_sqrt = np.sqrt(days)\n",
    "            day_of_week = col.dt.dayofweek\n",
    "            day = col.dt.day\n",
    "            month = col.dt.month\n",
    "            year = col.dt.year\n",
    "            \n",
    "            names = ['days', 'days_log', 'days_sqrt', 'day_of_week',\n",
    "                     'day', 'month', 'year']\n",
    "            cols = [days, days_log, days_sqrt, day_of_week,\n",
    "                    day, month, year]\n",
    "            \n",
    "            self.names = [*self.names,\n",
    "                          *['{}_{}'.format(name, n) for n in names]]\n",
    "            dfs = [*dfs, *cols]\n",
    "        \n",
    "        return pd.concat(dfs, axis=1)\n",
    "    \n",
    "    def get_feature_names(self):\n",
    "        return self.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDaysTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.base = SimpleImputer(missing_values=999.0,\n",
    "                                  strategy='mean',\n",
    "                                  add_indicator=True)\n",
    "    \n",
    "    def fit(self, X, **fit_params):\n",
    "        self.base.fit(X, **fit_params)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, **fit_params):\n",
    "        self.names = []\n",
    "        for name in X:\n",
    "            self.names.append(name)\n",
    "            self.names.append('{}_missing'.format(name))\n",
    "        \n",
    "        return self.base.transform(X, **fit_params)\n",
    "    \n",
    "    def get_feature_names(self):\n",
    "        return self.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.base = ColumnTransformer([\n",
    "                *[('{}_cat'.format(name), OneHotEncoder(), [name])\n",
    "                  for name in categorical if name != 'y'],\n",
    "                *[('{}_D'.format(name), DateTransformer(), [name])\n",
    "                  for name in datelike],\n",
    "                ('pdays', PDaysTransformer(), ['pdays']),\n",
    "                ('id', 'drop', ['id'])\n",
    "            ],\n",
    "            remainder='passthrough')\n",
    "    \n",
    "    def fit(self, X, **fit_params):\n",
    "        self.base.fit(X, **fit_params)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, **fit_params):\n",
    "        Xt = self.base.transform(X, **fit_params)\n",
    "        return pd.DataFrame(data=Xt, columns=self.get_feature_names())\n",
    "    \n",
    "    def get_feature_names(self):\n",
    "        return self.base.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.copy()\n",
    "labels = features.pop('y')\n",
    "features = StandardTransformer().fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Ix = (labels != 'unknown')\n",
    "train_features = features[train_Ix]\n",
    "train_labels = labels[train_Ix]\n",
    "\n",
    "from pandas.api.types import CategoricalDtype\n",
    "yn_type = CategoricalDtype(categories=['no', 'yes'], ordered=True)\n",
    "train_labels = pd.DataFrame(train_labels.astype(yn_type).cat.codes,\n",
    "                            columns=['y'])\n",
    "\n",
    "test_Ix = labels == 'unknown'\n",
    "test_features = features[test_Ix]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us also define some utility functions for further splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def _choose_Ix(train, n):\n",
    "    train_n = int(np.ceil(train*n))\n",
    "    train_Ix = np.random.choice(n, train_n, replace=False)\n",
    "    test_Ix = np.setdiff1d(np.arange(n), train_Ix)\n",
    "    return train_Ix, test_Ix\n",
    "\n",
    "def split(train, X=train_features, y=train_labels):\n",
    "    train_Ix, test_Ix = _choose_Ix(train, X.shape[0])\n",
    "    np.random.shuffle(train_Ix)\n",
    "    np.random.shuffle(test_Ix)    \n",
    "    \n",
    "    return X.iloc[train_Ix,:], X.iloc[test_Ix,:],\\\n",
    "           y.iloc[train_Ix,:], y.iloc[test_Ix,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model â„– 1 (`sklearn`) - Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_validate, RandomizedSearchCV,\\\n",
    "    GridSearchCV\n",
    "import tempfile\n",
    "\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import SGDClassifier, RidgeClassifierCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.ensemble import\\\n",
    "    AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier,\\\n",
    "    StackingClassifier, HistGradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_selection import SelectKBest, chi2, SelectFromModel\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following are the definitions of classifiers and grid parameters; in the previous version a `StackingClassifier` was used, but it was too slow and also yielded worse results (presumably it overfitted?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = {\n",
    "#     'rf': {\n",
    "#         'clf': RandomForestClassifier(),\n",
    "#         'grid': {\n",
    "#             'max_features': ['auto', 'sqrt', 'log2'],\n",
    "#             'n_estimators': [10, 100, 250, 1000],\n",
    "#         }\n",
    "#     },\n",
    "#     'et': {\n",
    "#         'clf': ExtraTreesClassifier(),\n",
    "#         'grid': {\n",
    "#             'n_estimators': [*range(50, 250+1, 50), 1000],\n",
    "#             'max_features': ['auto', 'sqrt', 'log2'],\n",
    "#             'min_samples_leaf': [*range(1, 10+1, 2), *range(20, 50+1, 5)],\n",
    "#             'min_samples_split': [*range(1, 10+1, 2), *range(15, 35+1, 5)]\n",
    "#         }\n",
    "#     },\n",
    "    'gbc': {\n",
    "        'clf': GradientBoostingClassifier(),\n",
    "        'grid': {\n",
    "            'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "            'n_estimators': [100, 200, 250, 300],\n",
    "            'max_features': ['auto', 'log2', 'sqrt'],\n",
    "            'max_depth': [*range(2, 5)],\n",
    "            'subsample': [0.7, 0.8, 1],\n",
    "        }\n",
    "    },\n",
    "    'ada': {\n",
    "        'clf': AdaBoostClassifier(),\n",
    "        'grid': {\n",
    "            'n_estimators': [10, 50, 100, 500],\n",
    "            'learning_rate': [0.01, 0.1, 0.5, 1, 2],\n",
    "            'base_estimator': [DecisionTreeClassifier(max_depth = n)\n",
    "                                    for n in [*range(1, 16+1)]]    \n",
    "        }\n",
    "    },\n",
    "    'xgb': {\n",
    "        'clf': XGBClassifier(use_label_encoder=False,\n",
    "                             eval_metric='logloss',\n",
    "                             subsample=0.8),\n",
    "        'grid': {\n",
    "#             'n_estimators': [10, 50, 100, 500],\n",
    "#             'learning_rate': [.02, .05, .1],\n",
    "#             'max_depth': [4, 6, 8, 10],\n",
    "        }\n",
    "    },\n",
    "#     'bayes': {\n",
    "#         'clf': GaussianNB(),\n",
    "#         'grid': {}\n",
    "#     }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part implements randomized search (for temporal reasons); the resultant model seemed suboptimal to the hand-picked values, though they were \"inspired\" by them. We optimize `GradientBoostingClassifier`, which seemed to work best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   23.6s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   55.9s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 165 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 205 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done 249 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=-1)]: Done 297 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done 322 tasks      | elapsed: 10.9min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed: 12.3min\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed: 13.2min\n",
      "[Parallel(n_jobs=-1)]: Done 405 tasks      | elapsed: 14.0min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 14.7min\n",
      "[Parallel(n_jobs=-1)]: Done 465 tasks      | elapsed: 15.2min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed: 15.7min finished\n"
     ]
    }
   ],
   "source": [
    "# # estimators = base\n",
    "# # clf = Pipeline([\n",
    "# #     ('stacked', StackingClassifier(\n",
    "# #         estimators=[(name, params['clf'])\n",
    "# #                     for name, params in estimators.items()],\n",
    "# #         final_estimator=GradientBoostingClassifier(),\n",
    "# #         n_jobs=2))\n",
    "# # ])\n",
    "# # clf = AdaBoostClassifier(n_estimators=250)\n",
    "\n",
    "# search = RandomizedSearchCV(base['gbc']['clf'], base['gbc']['grid'],\n",
    "#                             scoring='roc_auc', cv=5, n_jobs=-1, verbose=10,\n",
    "#                             n_iter=100)\n",
    "\n",
    "# X_train, _, y_train, _ = split(1)\n",
    "# y_train = np.ravel(y_train)\n",
    "# result = search.fit(X_train, y_train)\n",
    "\n",
    "# # score = cross_validate(clf, X_train, y_train,\n",
    "# #                        cv=5, scoring=['roc_auc'], verbose=10,\n",
    "# #                        return_estimator=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here we pick the model to run and save output to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pred_sk(clf, name):\n",
    "    pred_df = pd.DataFrame(columns=['id', 'y'])\n",
    "    pred_df['id'] = test_features.index+1\n",
    "    pred_df['y'] = clf.predict_proba(test_features)[:,1]\n",
    "    pred_df.to_csv('pred.{}.csv'.format(name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best = result.best_estimator_\n",
    "# best = GradientBoostingClassifier(learning_rate=0.05, max_depth=4,\n",
    "#                                   max_features='auto',\n",
    "#                                   subsample=0.7)\n",
    "best = GradientBoostingClassifier(n_estimators=250, subsample=0.8)\n",
    "save_pred_sk(best.fit(X_train, y_train), 'just')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beyond this point are unused models, mostly related to Tensorflow and Keras, which I toyed with (but which yielded results inferior to `sklearn`); mostly I wanted to learn how to use Keras if/when the time comes I need it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model â„– 2: `tf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras import layers\n",
    "# from tensorflow.keras.layers.experimental import preprocessing\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "# from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the definition of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPOCHS = 100\n",
    "# BATCH_SIZE = 2048\n",
    "# DROPOUT = 0.5\n",
    "\n",
    "# def block(x_in, size):\n",
    "#     x = layers.Dense(size)(x_in)\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "#     x = layers.Activation('relu')(x)\n",
    "#     x = layers.Dropout(DROPOUT)(x)\n",
    "#     return x\n",
    "\n",
    "# def create_model(shape):\n",
    "#     x_in = layers.Input(shape=shape)\n",
    "# #     x = block(x_in, 512)\n",
    "#     x = block(x_in, 512)\n",
    "# #     x = block(x, 512)\n",
    "# #     x = block(x, 128)\n",
    "#     x_out = layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "#     model = keras.Model(inputs=x_in, outputs=x_out)    \n",
    "#     model.compile(\n",
    "#         optimizer=keras.optimizers.Adam(lr=1e-3),\n",
    "#         loss=keras.losses.BinaryCrossentropy(),\n",
    "#         metrics=[keras.metrics.AUC(name='auc')])\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will want to balance the predictors in this particular case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = split(0.8, train_features, train_labels)\n",
    "\n",
    "# resample = False\n",
    "\n",
    "# if resample:\n",
    "#     neg_features = X_train[y_train == 0]\n",
    "#     neg_labels = y_train[y_train == 0]\n",
    "#     pos_features = X_train[y_train == 1]\n",
    "#     pos_labels = y_train[y_train == 1]\n",
    "\n",
    "#     def make_ds(features, labels):\n",
    "#         ds = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "#         ds = ds.shuffle(100000).repeat()\n",
    "#         return ds\n",
    "\n",
    "#     neg_ds = make_ds(neg_features, neg_labels)\n",
    "#     pos_ds = make_ds(pos_features, pos_labels)\n",
    "\n",
    "#     train_ds = tf.data.experimental.\\\n",
    "#         sample_from_datasets([neg_ds, pos_ds], weights=[0.5, 0.5])\n",
    "#     train_ds = train_ds.batch(BATCH_SIZE).prefetch(2)\n",
    "    \n",
    "#     pos = np.sum(y_train)\n",
    "#     total = np.size(y_train)\n",
    "#     neg = total - pos\n",
    "#     resampled_steps_per_epoch = np.ceil(2.0*neg/BATCH_SIZE)\n",
    "# else:    \n",
    "#     train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).cache()\n",
    "#     train_ds = train_ds.batch(BATCH_SIZE).prefetch(2)\n",
    "\n",
    "# val_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).cache()\n",
    "# val_ds = val_ds.batch(BATCH_SIZE).prefetch(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.6701 - auc: 0.5297 - val_loss: 2.9488 - val_auc: 0.5278\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4424 - auc: 0.5748 - val_loss: 2.3059 - val_auc: 0.5380\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.4098 - auc: 0.6174 - val_loss: 0.9590 - val_auc: 0.5722\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.4020 - auc: 0.6423 - val_loss: 1.4493 - val_auc: 0.7431\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.3848 - auc: 0.6762 - val_loss: 2.5506 - val_auc: 0.7522\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.3913 - auc: 0.6573 - val_loss: 2.7575 - val_auc: 0.7191\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.3815 - auc: 0.6656 - val_loss: 3.2870 - val_auc: 0.6965\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.3739 - auc: 0.6780 - val_loss: 3.8916 - val_auc: 0.6312\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.3750 - auc: 0.6767 - val_loss: 3.0326 - val_auc: 0.6299\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.3682 - auc: 0.6845 - val_loss: 2.2284 - val_auc: 0.6181\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.3718 - auc: 0.6735 - val_loss: 1.5764 - val_auc: 0.6080\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.3657 - auc: 0.6906 - val_loss: 1.0385 - val_auc: 0.6028\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.3694 - auc: 0.6738 - val_loss: 0.7388 - val_auc: 0.5950\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.3679 - auc: 0.6866 - val_loss: 0.5601 - val_auc: 0.5936\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.3627 - auc: 0.6840 - val_loss: 0.3778 - val_auc: 0.6059\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.3644 - auc: 0.6814 - val_loss: 0.3554 - val_auc: 0.6436\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.3539 - auc: 0.7003 - val_loss: 0.3591 - val_auc: 0.6918\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.3547 - auc: 0.6973 - val_loss: 0.3683 - val_auc: 0.7341\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.3511 - auc: 0.7003 - val_loss: 0.3696 - val_auc: 0.7356\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.3505 - auc: 0.7005 - val_loss: 0.4029 - val_auc: 0.7337\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.3504 - auc: 0.7019 - val_loss: 0.4478 - val_auc: 0.6983\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.3505 - auc: 0.7018 - val_loss: 0.4680 - val_auc: 0.6754\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3483 - auc: 0.7071 - val_loss: 0.5495 - val_auc: 0.6164\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.3461 - auc: 0.6996 - val_loss: 0.5664 - val_auc: 0.5869\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.3452 - auc: 0.7051 - val_loss: 0.5633 - val_auc: 0.5803\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.3445 - auc: 0.7073 - val_loss: 0.6300 - val_auc: 0.5404\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.3437 - auc: 0.7022 - val_loss: 0.5857 - val_auc: 0.5530\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.3391 - auc: 0.7157 - val_loss: 0.5061 - val_auc: 0.5809\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.3417 - auc: 0.7115 - val_loss: 0.5654 - val_auc: 0.5419\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.3374 - auc: 0.7145 - val_loss: 0.4936 - val_auc: 0.5364\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.3363 - auc: 0.7168 - val_loss: 0.4887 - val_auc: 0.5339\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.3372 - auc: 0.7129 - val_loss: 0.4535 - val_auc: 0.5498\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3391 - auc: 0.7137 - val_loss: 0.4634 - val_auc: 0.5588\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.3322 - auc: 0.7231 - val_loss: 0.4807 - val_auc: 0.5563\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.3336 - auc: 0.7195 - val_loss: 0.5343 - val_auc: 0.5469\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.3315 - auc: 0.7221 - val_loss: 0.4961 - val_auc: 0.5603\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.3309 - auc: 0.7247 - val_loss: 0.5183 - val_auc: 0.5671\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3312 - auc: 0.7180 - val_loss: 0.5358 - val_auc: 0.5653\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3298 - auc: 0.7282 - val_loss: 0.5314 - val_auc: 0.5698\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3311 - auc: 0.7200 - val_loss: 0.5551 - val_auc: 0.5712\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.3268 - auc: 0.7337 - val_loss: 0.6069 - val_auc: 0.5587\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.3272 - auc: 0.7278 - val_loss: 0.5661 - val_auc: 0.5602\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.3255 - auc: 0.7316 - val_loss: 0.5896 - val_auc: 0.5480\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.3231 - auc: 0.7337 - val_loss: 0.5357 - val_auc: 0.5558\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.3268 - auc: 0.7272 - val_loss: 0.5049 - val_auc: 0.5644\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.3247 - auc: 0.7304 - val_loss: 0.5149 - val_auc: 0.5617\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.3226 - auc: 0.7344 - val_loss: 0.5793 - val_auc: 0.5518\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.3281 - auc: 0.7219 - val_loss: 0.5571 - val_auc: 0.5608\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.3223 - auc: 0.7356 - val_loss: 0.5169 - val_auc: 0.5648\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.3210 - auc: 0.7351 - val_loss: 0.5058 - val_auc: 0.5927\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3200 - auc: 0.7370 - val_loss: 0.5714 - val_auc: 0.5881\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.3212 - auc: 0.7331 - val_loss: 0.5454 - val_auc: 0.5975\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.3175 - auc: 0.7437 - val_loss: 0.5748 - val_auc: 0.5993\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.3200 - auc: 0.7358 - val_loss: 0.4989 - val_auc: 0.6081\n",
      "Epoch 55/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3166 - auc: 0.7442 - val_loss: 0.4238 - val_auc: 0.6138\n",
      "Epoch 56/100\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.3208 - auc: 0.7348 - val_loss: 0.4450 - val_auc: 0.5942\n",
      "Epoch 57/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3169 - auc: 0.7445 - val_loss: 0.4199 - val_auc: 0.5978\n",
      "Epoch 58/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.3155 - auc: 0.7444 - val_loss: 0.4033 - val_auc: 0.6231\n",
      "Epoch 59/100\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.3164 - auc: 0.7448 - val_loss: 0.4240 - val_auc: 0.6158\n",
      "Epoch 60/100\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.3180 - auc: 0.7389 - val_loss: 0.4326 - val_auc: 0.6244\n",
      "Epoch 61/100\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.3154 - auc: 0.7454 - val_loss: 0.4178 - val_auc: 0.6447\n",
      "Epoch 62/100\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.3172 - auc: 0.7376 - val_loss: 0.4123 - val_auc: 0.6404\n",
      "Epoch 63/100\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.3155 - auc: 0.7417 - val_loss: 0.4097 - val_auc: 0.6310\n",
      "Epoch 64/100\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.3141 - auc: 0.7444 - val_loss: 0.4027 - val_auc: 0.6242\n",
      "Epoch 65/100\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.3132 - auc: 0.7478 - val_loss: 0.4220 - val_auc: 0.6223\n",
      "Epoch 66/100\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.3118 - auc: 0.7486 - val_loss: 0.4007 - val_auc: 0.6353\n",
      "Epoch 67/100\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.3144 - auc: 0.7416 - val_loss: 0.3463 - val_auc: 0.6871\n",
      "Epoch 68/100\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.3135 - auc: 0.7439 - val_loss: 0.3458 - val_auc: 0.6793\n",
      "Epoch 69/100\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.3145 - auc: 0.7440 - val_loss: 0.3632 - val_auc: 0.6565\n",
      "Epoch 70/100\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.3144 - auc: 0.7447 - val_loss: 0.3478 - val_auc: 0.6755\n",
      "Epoch 71/100\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.3112 - auc: 0.7467 - val_loss: 0.3644 - val_auc: 0.6488\n",
      "Epoch 72/100\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.3125 - auc: 0.7482 - val_loss: 0.3425 - val_auc: 0.6881\n",
      "Epoch 73/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3128 - auc: 0.7489 - val_loss: 0.3354 - val_auc: 0.7080\n",
      "Epoch 74/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3098 - auc: 0.7503 - val_loss: 0.3707 - val_auc: 0.6814\n",
      "Epoch 75/100\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.3102 - auc: 0.7519 - val_loss: 0.3340 - val_auc: 0.7038\n",
      "Epoch 76/100\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.3127 - auc: 0.7452 - val_loss: 0.3491 - val_auc: 0.6759\n",
      "Epoch 77/100\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.3096 - auc: 0.7481 - val_loss: 0.3622 - val_auc: 0.6625\n",
      "Epoch 78/100\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.3095 - auc: 0.7496 - val_loss: 0.3463 - val_auc: 0.6797\n",
      "Epoch 79/100\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.3127 - auc: 0.7449 - val_loss: 0.4542 - val_auc: 0.6255\n",
      "Epoch 80/100\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.3107 - auc: 0.7514 - val_loss: 0.3857 - val_auc: 0.6337\n",
      "Epoch 81/100\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.3117 - auc: 0.7516 - val_loss: 0.3493 - val_auc: 0.6861\n",
      "Epoch 82/100\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.3125 - auc: 0.7452 - val_loss: 0.3669 - val_auc: 0.6871\n",
      "Epoch 83/100\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.3105 - auc: 0.7517 - val_loss: 0.3646 - val_auc: 0.6663\n",
      "Epoch 84/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.3077 - auc: 0.7524 - val_loss: 0.3862 - val_auc: 0.6400\n",
      "Epoch 85/100\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.3110 - auc: 0.7486 - val_loss: 0.4259 - val_auc: 0.6120\n",
      "Epoch 86/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.3060 - auc: 0.7607 - val_loss: 0.4416 - val_auc: 0.6290\n",
      "Epoch 87/100\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.3100 - auc: 0.7518 - val_loss: 0.3804 - val_auc: 0.6581\n",
      "Epoch 88/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3066 - auc: 0.7568 - val_loss: 0.3543 - val_auc: 0.6797\n",
      "Epoch 89/100\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 0.3098 - auc: 0.7508 - val_loss: 0.3697 - val_auc: 0.6378\n",
      "Epoch 90/100\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.3079 - auc: 0.7545 - val_loss: 0.3863 - val_auc: 0.6452\n",
      "Epoch 91/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3103 - auc: 0.7466 - val_loss: 0.3287 - val_auc: 0.7311\n",
      "Epoch 92/100\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.3078 - auc: 0.7553 - val_loss: 0.3330 - val_auc: 0.7695\n",
      "Epoch 93/100\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.3060 - auc: 0.7580 - val_loss: 0.3330 - val_auc: 0.7270\n",
      "Epoch 94/100\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.3066 - auc: 0.7537 - val_loss: 0.3307 - val_auc: 0.7307\n",
      "Epoch 95/100\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.3080 - auc: 0.7530 - val_loss: 0.3237 - val_auc: 0.7557\n",
      "Epoch 96/100\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.3054 - auc: 0.7569 - val_loss: 0.3468 - val_auc: 0.7166\n",
      "Epoch 97/100\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.3056 - auc: 0.7566 - val_loss: 0.3230 - val_auc: 0.7457\n",
      "Epoch 98/100\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.3045 - auc: 0.7606 - val_loss: 0.3180 - val_auc: 0.7586\n",
      "Epoch 99/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3049 - auc: 0.7574 - val_loss: 0.3276 - val_auc: 0.7386\n",
      "Epoch 100/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.3039 - auc: 0.7620 - val_loss: 0.3339 - val_auc: 0.7345\n"
     ]
    }
   ],
   "source": [
    "# model = create_model(X_train.shape[1])\n",
    "\n",
    "# early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "#     monitor='val_auc', \n",
    "#     verbose=1,\n",
    "#     patience=10,\n",
    "#     mode='max',\n",
    "#     restore_best_weights=True)\n",
    "\n",
    "# history = model.fit(\n",
    "#     train_ds,\n",
    "#     epochs=EPOCHS,\n",
    "# #     steps_per_epoch=resampled_steps_per_epoch,\n",
    "# #     callbacks=[early_stopping],\n",
    "#     validation_data=val_ds,\n",
    "#     verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let us save the predictions to a .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_pred_tf(model, name):\n",
    "#     pred_df = pd.DataFrame(columns=['id', 'y'])\n",
    "#     pred_df['id'] = test_features.index+1\n",
    "#     pred_df['y'] = model.predict(test_features)\n",
    "#     pred_df.to_csv('pred.{}.csv'.format(name), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model â„– 3: `tf` *and* `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea (a perhaps-bad one) is for a Keras model to construct a \"latent representation\" of the feature space, which we will add to the usual feature space and all that to the `sklearn` classifier from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV #1\n",
      "Epoch 1/100\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 1.1316 - auc: 0.5404"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-9551651f5357>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CV #{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_keras_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-9551651f5357>\u001b[0m in \u001b[0;36mtrain_keras_model\u001b[0;34m(X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     history = model.fit(\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/devs/venvs/py38/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/devs/venvs/py38/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/devs/venvs/py38/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/devs/venvs/py38/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/devs/venvs/py38/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/devs/venvs/py38/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/devs/venvs/py38/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/devs/venvs/py38/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/devs/venvs/py38/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# def make_sets():\n",
    "#     sss = StratifiedShuffleSplit(n_splits=5, test_size=0.25)\n",
    "#     sss.get_n_splits(train_features, train_labels)\n",
    "\n",
    "#     for train_Ix, test_Ix in sss.split(train_features, train_labels):\n",
    "#         X_train = train_features.iloc[train_Ix,:]\n",
    "#         y_train = train_labels.iloc[train_Ix,:]\n",
    "#         X_test = train_features.iloc[test_Ix,:]\n",
    "#         y_test = train_labels.iloc[test_Ix,:]\n",
    "#         yield X_train, X_test, y_train, y_test\n",
    "\n",
    "# def make_ds(X, y):\n",
    "#     ds = tf.data.Dataset.from_tensor_slices((X, y)).cache()\n",
    "#     return ds.batch(BATCH_SIZE).prefetch(2)\n",
    "        \n",
    "# def train_keras_model(X_train, X_test, y_train, y_test):\n",
    "#     train_ds = make_ds(X_train, y_train)\n",
    "#     val_ds = make_ds(X_test, y_test)\n",
    "    \n",
    "#     model = create_model(X_train.shape[1])\n",
    "#     history = model.fit(\n",
    "#         train_ds,\n",
    "#         epochs=EPOCHS,\n",
    "#         validation_data=val_ds)\n",
    "    \n",
    "#     return model\n",
    "\n",
    "# def train_sklearn_clf(X_train, y_train):\n",
    "#     estimators = base\n",
    "#     clf = Pipeline([\n",
    "#         ('stacked', StackingClassifier(\n",
    "#             estimators=[(name, params['clf'])\n",
    "#                         for name, params in estimators.items()],\n",
    "#             final_estimator=GradientBoostingClassifier(),\n",
    "#             n_jobs=2, verbose=1))\n",
    "#     ])\n",
    "#     return clf.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "# def encoder_for(model):\n",
    "#     return keras.models.Model(model.input, model.layers[-2].output)\n",
    "\n",
    "# def add_latent(encoder, X):\n",
    "#     latent = encoder.predict(X)\n",
    "#     cols = ['L{}'.format(i) for i in range(latent.shape[1])]\n",
    "#     latent = pd.DataFrame(index=X.index, data=latent, columns=cols)\n",
    "#     return pd.concat([X, latent], axis=1)\n",
    "\n",
    "# for i, (X_train, X_test, y_train, y_test) in enumerate(make_sets(), 1):\n",
    "#     print('CV #{}'.format(i))\n",
    "    \n",
    "#     model = train_keras_model(X_train, X_test, y_train, y_test)\n",
    "#     encoder = encoder_for(model)\n",
    "    \n",
    "#     X_train = add_latent(encoder, X_train)\n",
    "#     X_test = add_latent(encoder, X_test)\n",
    "    \n",
    "#     clf = train_sklearn_clf(X_train, y_train)\n",
    "    \n",
    "#     X_test_pred = clf.predict_proba(X_test)[:,1]\n",
    "#     score = roc_auc_score(y_test, X_test_pred)\n",
    "#     print('roc_auc_score -> {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 2s 222ms/step - loss: 0.6129 - auc: 0.6333 - val_loss: 9.5593 - val_auc: 0.5723\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 2s 210ms/step - loss: 0.4438 - auc: 0.6519 - val_loss: 3.0034 - val_auc: 0.7097\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 2s 193ms/step - loss: 0.3739 - auc: 0.6730 - val_loss: 2.8017 - val_auc: 0.7170\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 2s 197ms/step - loss: 0.3480 - auc: 0.6953 - val_loss: 1.8835 - val_auc: 0.7359\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 2s 212ms/step - loss: 0.3348 - auc: 0.7214 - val_loss: 1.2260 - val_auc: 0.7374\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 2s 202ms/step - loss: 0.3345 - auc: 0.7159 - val_loss: 1.0009 - val_auc: 0.7357\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 2s 199ms/step - loss: 0.3275 - auc: 0.7334 - val_loss: 0.8297 - val_auc: 0.7280\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 2s 204ms/step - loss: 0.3235 - auc: 0.7341 - val_loss: 0.6432 - val_auc: 0.7227\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 2s 196ms/step - loss: 0.3226 - auc: 0.7374 - val_loss: 0.6204 - val_auc: 0.7255\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 2s 184ms/step - loss: 0.3218 - auc: 0.7380 - val_loss: 0.6018 - val_auc: 0.7321\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 2s 183ms/step - loss: 0.3184 - auc: 0.7462 - val_loss: 0.5552 - val_auc: 0.7295\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 2s 182ms/step - loss: 0.3212 - auc: 0.7356 - val_loss: 0.5170 - val_auc: 0.7226\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 2s 183ms/step - loss: 0.3184 - auc: 0.7425 - val_loss: 0.4964 - val_auc: 0.7289\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 2s 183ms/step - loss: 0.3176 - auc: 0.7404 - val_loss: 0.4714 - val_auc: 0.7356\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 2s 186ms/step - loss: 0.3183 - auc: 0.7390 - val_loss: 0.4476 - val_auc: 0.7344\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 2s 184ms/step - loss: 0.3128 - auc: 0.7493 - val_loss: 0.4194 - val_auc: 0.7364\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 2s 186ms/step - loss: 0.3164 - auc: 0.7405 - val_loss: 0.3995 - val_auc: 0.7384\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 2s 185ms/step - loss: 0.3119 - auc: 0.7481 - val_loss: 0.3875 - val_auc: 0.7421\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 2s 185ms/step - loss: 0.3123 - auc: 0.7493 - val_loss: 0.3745 - val_auc: 0.7423\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 2s 184ms/step - loss: 0.3154 - auc: 0.7425 - val_loss: 0.3696 - val_auc: 0.7413\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 2s 188ms/step - loss: 0.3134 - auc: 0.7426 - val_loss: 0.3587 - val_auc: 0.7434\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 2s 192ms/step - loss: 0.3141 - auc: 0.7424 - val_loss: 0.3547 - val_auc: 0.7447\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 2s 194ms/step - loss: 0.3107 - auc: 0.7474 - val_loss: 0.3482 - val_auc: 0.7456\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 2s 191ms/step - loss: 0.3098 - auc: 0.7478 - val_loss: 0.3500 - val_auc: 0.7440\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 2s 193ms/step - loss: 0.3086 - auc: 0.7495 - val_loss: 0.3472 - val_auc: 0.7452\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 2s 190ms/step - loss: 0.3058 - auc: 0.7543 - val_loss: 0.3382 - val_auc: 0.7466\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 2s 193ms/step - loss: 0.3124 - auc: 0.7422 - val_loss: 0.3389 - val_auc: 0.7459\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 2s 190ms/step - loss: 0.3095 - auc: 0.7499 - val_loss: 0.3405 - val_auc: 0.7443\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 2s 190ms/step - loss: 0.3079 - auc: 0.7512 - val_loss: 0.3270 - val_auc: 0.7477\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 2s 190ms/step - loss: 0.3055 - auc: 0.7558 - val_loss: 0.3295 - val_auc: 0.7473\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 2s 192ms/step - loss: 0.3046 - auc: 0.7596 - val_loss: 0.3232 - val_auc: 0.7469\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 2s 192ms/step - loss: 0.3041 - auc: 0.7577 - val_loss: 0.3271 - val_auc: 0.7446\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 2s 193ms/step - loss: 0.3055 - auc: 0.7556 - val_loss: 0.3330 - val_auc: 0.7425\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 2s 188ms/step - loss: 0.3034 - auc: 0.7574 - val_loss: 0.3291 - val_auc: 0.7410\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 2s 193ms/step - loss: 0.3061 - auc: 0.7529 - val_loss: 0.3310 - val_auc: 0.7399\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 2s 190ms/step - loss: 0.3050 - auc: 0.7550 - val_loss: 0.3343 - val_auc: 0.7398\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 2s 193ms/step - loss: 0.3043 - auc: 0.7555 - val_loss: 0.3260 - val_auc: 0.7415\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 2s 191ms/step - loss: 0.3064 - auc: 0.7490 - val_loss: 0.3263 - val_auc: 0.7409\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 2s 193ms/step - loss: 0.3039 - auc: 0.7556 - val_loss: 0.3179 - val_auc: 0.7439\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 2s 189ms/step - loss: 0.3038 - auc: 0.7560 - val_loss: 0.3207 - val_auc: 0.7427\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 2s 192ms/step - loss: 0.3041 - auc: 0.7576 - val_loss: 0.3160 - val_auc: 0.7452\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 2s 191ms/step - loss: 0.3043 - auc: 0.7523 - val_loss: 0.3188 - val_auc: 0.7436\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 2s 194ms/step - loss: 0.3027 - auc: 0.7549 - val_loss: 0.3205 - val_auc: 0.7454\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 2s 188ms/step - loss: 0.3034 - auc: 0.7545 - val_loss: 0.3142 - val_auc: 0.7472\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 2s 224ms/step - loss: 0.3025 - auc: 0.7594 - val_loss: 0.3122 - val_auc: 0.7483\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 2s 216ms/step - loss: 0.3029 - auc: 0.7585 - val_loss: 0.3141 - val_auc: 0.7465\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 2s 195ms/step - loss: 0.3014 - auc: 0.7594 - val_loss: 0.3111 - val_auc: 0.7473\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 2s 206ms/step - loss: 0.3027 - auc: 0.7549 - val_loss: 0.3157 - val_auc: 0.7439\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 2s 227ms/step - loss: 0.3012 - auc: 0.7614 - val_loss: 0.3182 - val_auc: 0.7440\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 2s 196ms/step - loss: 0.3040 - auc: 0.7499 - val_loss: 0.3171 - val_auc: 0.7440\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 2s 205ms/step - loss: 0.3001 - auc: 0.7646 - val_loss: 0.3138 - val_auc: 0.7442\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 2s 200ms/step - loss: 0.3013 - auc: 0.7586 - val_loss: 0.3163 - val_auc: 0.7439\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 2s 198ms/step - loss: 0.3003 - auc: 0.7628 - val_loss: 0.3112 - val_auc: 0.7452\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 2s 203ms/step - loss: 0.2995 - auc: 0.7623 - val_loss: 0.3159 - val_auc: 0.7423\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 2s 223ms/step - loss: 0.3006 - auc: 0.7607 - val_loss: 0.3135 - val_auc: 0.7442\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 2s 227ms/step - loss: 0.3011 - auc: 0.7600 - val_loss: 0.3207 - val_auc: 0.7419\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 2s 238ms/step - loss: 0.3004 - auc: 0.7598 - val_loss: 0.3087 - val_auc: 0.7470\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 2s 216ms/step - loss: 0.2996 - auc: 0.7627 - val_loss: 0.3096 - val_auc: 0.7477\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 2s 206ms/step - loss: 0.3003 - auc: 0.7600 - val_loss: 0.3083 - val_auc: 0.7502\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 2s 218ms/step - loss: 0.3006 - auc: 0.7584 - val_loss: 0.3068 - val_auc: 0.7507\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 3s 269ms/step - loss: 0.2991 - auc: 0.7653 - val_loss: 0.3082 - val_auc: 0.7463\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 2s 247ms/step - loss: 0.2988 - auc: 0.7608 - val_loss: 0.3147 - val_auc: 0.7412\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 3s 253ms/step - loss: 0.2993 - auc: 0.7629 - val_loss: 0.3220 - val_auc: 0.7392\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 2s 200ms/step - loss: 0.3003 - auc: 0.7591 - val_loss: 0.3159 - val_auc: 0.7406\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 2s 205ms/step - loss: 0.2981 - auc: 0.7655 - val_loss: 0.3219 - val_auc: 0.7378\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 2s 204ms/step - loss: 0.2986 - auc: 0.7648 - val_loss: 0.3137 - val_auc: 0.7416\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 2s 223ms/step - loss: 0.3002 - auc: 0.7588 - val_loss: 0.3122 - val_auc: 0.7444\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 2s 236ms/step - loss: 0.2998 - auc: 0.7586 - val_loss: 0.3112 - val_auc: 0.7464\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 2s 227ms/step - loss: 0.2983 - auc: 0.7647 - val_loss: 0.3088 - val_auc: 0.7477\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 2s 201ms/step - loss: 0.2970 - auc: 0.7674 - val_loss: 0.3068 - val_auc: 0.7533\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 2s 201ms/step - loss: 0.2984 - auc: 0.7637 - val_loss: 0.3171 - val_auc: 0.7437\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 2s 210ms/step - loss: 0.2984 - auc: 0.7654 - val_loss: 0.3061 - val_auc: 0.7522\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 2s 207ms/step - loss: 0.2988 - auc: 0.7633 - val_loss: 0.3079 - val_auc: 0.7477\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 2s 201ms/step - loss: 0.2982 - auc: 0.7643 - val_loss: 0.3084 - val_auc: 0.7481\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 2s 209ms/step - loss: 0.2984 - auc: 0.7626 - val_loss: 0.3106 - val_auc: 0.7464\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 2s 208ms/step - loss: 0.2975 - auc: 0.7660 - val_loss: 0.3219 - val_auc: 0.7408\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 2s 203ms/step - loss: 0.2968 - auc: 0.7695 - val_loss: 0.3294 - val_auc: 0.7406\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 2s 225ms/step - loss: 0.2973 - auc: 0.7653 - val_loss: 0.3330 - val_auc: 0.7408\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 2s 232ms/step - loss: 0.2968 - auc: 0.7645 - val_loss: 0.3377 - val_auc: 0.7402\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 2s 232ms/step - loss: 0.2971 - auc: 0.7676 - val_loss: 0.3148 - val_auc: 0.7441\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 2s 221ms/step - loss: 0.2959 - auc: 0.7702 - val_loss: 0.3173 - val_auc: 0.7431\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 2s 215ms/step - loss: 0.2970 - auc: 0.7661 - val_loss: 0.3069 - val_auc: 0.7500\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 2s 221ms/step - loss: 0.2988 - auc: 0.7611 - val_loss: 0.3132 - val_auc: 0.7454\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 2s 195ms/step - loss: 0.2979 - auc: 0.7659 - val_loss: 0.3138 - val_auc: 0.7463\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 2s 209ms/step - loss: 0.2960 - auc: 0.7682 - val_loss: 0.3108 - val_auc: 0.7483\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 2s 191ms/step - loss: 0.2968 - auc: 0.7696 - val_loss: 0.3189 - val_auc: 0.7448\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 2s 188ms/step - loss: 0.2985 - auc: 0.7637 - val_loss: 0.3071 - val_auc: 0.7499\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 2s 205ms/step - loss: 0.2969 - auc: 0.7660 - val_loss: 0.3088 - val_auc: 0.7491\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 2s 193ms/step - loss: 0.2969 - auc: 0.7673 - val_loss: 0.3066 - val_auc: 0.7498\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 2s 198ms/step - loss: 0.2969 - auc: 0.7661 - val_loss: 0.3077 - val_auc: 0.7484\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 2s 192ms/step - loss: 0.2973 - auc: 0.7641 - val_loss: 0.3101 - val_auc: 0.7469\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 2s 213ms/step - loss: 0.2969 - auc: 0.7670 - val_loss: 0.3169 - val_auc: 0.7441\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 2s 201ms/step - loss: 0.2959 - auc: 0.7677 - val_loss: 0.3112 - val_auc: 0.7473\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 2s 236ms/step - loss: 0.2959 - auc: 0.7668 - val_loss: 0.3065 - val_auc: 0.7514\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 2s 233ms/step - loss: 0.2957 - auc: 0.7696 - val_loss: 0.3104 - val_auc: 0.7496\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 2s 191ms/step - loss: 0.2961 - auc: 0.7704 - val_loss: 0.3167 - val_auc: 0.7439\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 2s 238ms/step - loss: 0.2950 - auc: 0.7682 - val_loss: 0.3165 - val_auc: 0.7433\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 2s 208ms/step - loss: 0.2970 - auc: 0.7640 - val_loss: 0.3119 - val_auc: 0.7447\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 2s 194ms/step - loss: 0.2965 - auc: 0.7679 - val_loss: 0.3065 - val_auc: 0.7503\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 2s 230ms/step - loss: 0.2968 - auc: 0.7623 - val_loss: 0.3094 - val_auc: 0.7485\n",
      "WARNING:tensorflow:From /home/talos/devs/venvs/py38/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /home/talos/devs/venvs/py38/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: model2/assets\n"
     ]
    }
   ],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(train_features, train_labels, test_size=0.1)\n",
    "\n",
    "# model = train_keras_model(X_train, X_test, y_train, y_test)\n",
    "# model.save('model2')\n",
    "# encoder = encoder_for(model)\n",
    "\n",
    "# X_train = add_latent(encoder, X_train)\n",
    "# clf = train_sklearn_clf(X_train, y_train)\n",
    "\n",
    "# lat_test_features = add_latent(encoder, test_features)\n",
    "\n",
    "# name = 'synth'\n",
    "# pred_df = pd.DataFrame(columns=['id', 'y'])\n",
    "# pred_df['id'] = test_features.index+1\n",
    "# pred_df['y'] = clf.predict_proba(lat_test_features)[:,1]\n",
    "# pred_df.to_csv('pred.{}.csv'.format(name), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
